{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Plan Smart o Ultra?  \n",
    "**Un modelo de clasificación para hacer las recomendaciones correctas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este proyecto es crear un modelo de machine learning que recomiende el plan telefónico correcto para los clientes de una empresa telefónica llamada Megaline, esto con ayuda de la información recopilada sobre los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos. Para ello, se utilizarán diferentes modelos e hiperparámetros con el fin de investigar cuál es el modelo con la mayor exactitud posible y así asegurar la máxima calidad de las respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-procesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar todas las librerías necesarias para este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Para la manipulación, lectura y análisis de datos\n",
    "from sklearn.model_selection import train_test_split # Para dividir los datos en distintos conjuntos\n",
    "from sklearn.metrics import accuracy_score # Para medir la exactitud del modelo de clasificación\n",
    "from sklearn.tree import DecisionTreeClassifier # Para implementar el modelo de árboles de decisión\n",
    "from sklearn.ensemble import RandomForestClassifier # Para implementar el modelo de bosque aleatorio\n",
    "from sklearn.linear_model import LogisticRegression # Para implementar el modelo de regresión logística\n",
    "from sklearn.dummy import DummyClassifier # Para crear modelos tontos que no aprenden de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se debe hacer la lectura de los datos y verificar que sean correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv') # Lectura del dataset\n",
    "print(df.head(10)) # Imprimir las primeras 10 filas\n",
    "rows, columns = df.shape # Conocer el número de filas y columnas\n",
    "print(f'Número de filas: {rows} \\nNúmero de columnas: {columns}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info() # Con ayuda de info() verificaremos que no haya valores nulos y los tipos sean correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segmentación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario dividir el dataset en tres partes debido a que no se tiene un conjunto de prueba externo. Para ello, se dividirá en: \n",
    "1. **Conjunto de entrenamiento**, para ajustar los parámetros del modelo. \n",
    "2. **Conjunto de validación**, para elegir los hiperparámetros y modelos.\n",
    "3. **Conjunto de prueba**, para su evaluación final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El primer paso es definir las variables target y features\n",
    "target = df['is_ultra']\n",
    "features = df.drop('is_ultra', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El segundo paso es hacer la división usando train_test_split\n",
    "\n",
    " #El 40% de los datos originales se asignará a la variable _temp y el 60% restante a _train\n",
    "target_train, target_temp, features_train, features_temp = train_test_split(target, features, test_size=0.40, random_state=54321)\n",
    "\n",
    "# Se tomará el 50% de df_temp para df_test y el otro 50% para df_valid, teniendo el 20% de los datos para cada uno\n",
    "target_valid, target_test, features_valid, features_test = train_test_split(target_temp, features_temp, test_size=0.50, random_state=54321) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Manipulación de los hiperparámetros para encontrar el modelo con mejor desempeño\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario investigar la calidad de diferentes modelos para encontrar el adecuado, para ello se probaran distintos modelos de clasificación (DecisionTreeClassifier, RandomForestClassifier, LogisticRegression) y se manipularán sus hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El primer modelo a probar será el de árbol de decisión:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilizaremos un bucle for para ajustar max_depth en un rango de 1 a 10\n",
    "for depth in range(1, 11): \n",
    "        model = DecisionTreeClassifier(random_state=54321, max_depth=depth) # Se ajustan los hiperparámetros\n",
    "        model.fit(features_train, target_train) # Se entrena al modelo usando los datos de entrenamiento\n",
    "        train_prediction = model.predict(features_train) # Realiza predicciones sobre el mismo conjunto de entrenamiento\n",
    "        valid_prediction = model.predict(features_valid) # Realiza predicciones sobre el conjunto de validación, esto para elegir la mejor profundidad\n",
    "        accuracy= accuracy_score(target_valid, valid_prediction) # Compara las predicciones del modelo en el conjunto de validación (valid_prediction) con las verdaderas etiquetas (target_valid)\n",
    "        print(f\"DecisionTreeClassifier max_depth={depth}: Exactitud = {accuracy:}\") # Imprime el nivel de profundidad con su exactitud correspondiente\n",
    "\n",
    "# Ahora se hará una condición if que comparará las puntuaciones de exactitud \n",
    "        best_model= None # Inicialmente no se ha determinado cuál es el mejor modelo, por eso se asigna None\n",
    "        best_accuracy = 0.0 # Guarda la mejor exactitud encontrada hasta el momento, iniciando en 0.0 porque aún no ha probado ningún modelo\n",
    "        best_params = None # Contendrá los paraámetros del mejor modelo.\n",
    "    \n",
    "        # Se comprueba si la exactitud obtenida con el max_depth actual es mejor que la mejor exactitud encontrada hasta el momento (best_accuracy)\n",
    "        if accuracy > best_accuracy: # Si es mejor, entonces cambia los valores\n",
    "                best_accuracy = accuracy \n",
    "                best_model = model\n",
    "        \n",
    "print(\"Mejor exactitud con Árbol de decisión:\", accuracy.max(), \"con max_depth:\", depth)\n",
    "print()\n",
    "print(f\"Mejor modelo hasta ahora: {best_model}, con una exactitud de: {best_accuracy}\")\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El árbol de decisión mejora su exactitud a medida que aumenta la profundidad, alcanzando su punto más alto en max_depth=10 con una exactitud aproximada de 0.78. Esto indica que, para este conjunto de datos, un árbol más profundo logra capturar mejor las relaciones entre las características y el objetivo. Por lo tanto, hasta ahora el mejor modelo encontrado es un DecisionTree classifier con max_depth=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora probaremos con un bosque aleatorio, cambiando los hiperparámetros n_estimators y depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 11): # Utilizaremos un bucle for para ajustar n_estimators en un rango de 1 a 10\n",
    "    for depth in range(1, 11): \n",
    "        model = RandomForestClassifier(random_state=54321, n_estimators=n, max_depth=depth) # Definimos el modelo\n",
    "        model.fit(features_train, target_train) # Entrenamos al modelo\n",
    "        valid_prediction = model.predict(features_valid) # Realiza predicciones sobre el conjunto de validación\n",
    "        accuracy = accuracy_score(target_valid, valid_prediction) # Evaluamos las predicciones anteriores comparándolas con las respuestas correctas\n",
    "        print(f\"RandomForest n_estimators={n}, max_depth={depth}: Exactitud = {accuracy:}\")\n",
    "        \n",
    "# Ahora haremos una comparación de los porcentajes de exactitud y si este resulta mayor al del modelo anterior, los valores se actualizaran\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_params = {\"model\": \"RandomForest\", \"n_estimators\": n, \"max_depth\": depth}\n",
    "print()        \n",
    "print(\"Mejor exactitud con Bosque Aleatorio:\", accuracy.max())\n",
    "print()\n",
    "print(f\"Mejor modelo hasta ahora: {best_model}, con una exactitud de: {best_accuracy}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El experimento de hiperparámetros con RandomForestClassifier muestra que el rendimiento mejora con más estimadores (n_estimators) y mayor profundidad del árbol. Tras evaluar distintas combinaciones en el rango de n_estimators= 1 a 10 y max_depth= 1 a 10, se encontró que el mejor resultado se obtiene con max_depth=10 y n_estimators = 8 o 10. Este modelo alcanza una exactitud aproximada de 0.80 y supera al modelo anterior, demostrando que ajustar adecuadamente los hiperparámetros puede mejorar de manera significativa el rendimiento del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finalmente probaremos con una prueba de Regresión Logística\n",
    "model = LogisticRegression(random_state=54321, solver='liblinear') # En este modelo no se cambian los hiperparámetros, sólo se asigna el algoritmo que optimiza el modelo\n",
    "model.fit(features_train, target_train) # Se entrena el modelo\n",
    "predictions = model.predict(features_valid) # Se hacen las predicciones con características nuevas\n",
    "accuracy = accuracy_score(target_valid, predictions) # Se comparan las predicciones con las respuestas correctas\n",
    "print(f\"LogisticRegression, Exactitud = {accuracy}\")\n",
    "print()\n",
    "\n",
    "# Se comparan las puntuaciones con los modelos anteriores\n",
    "if accuracy > best_accuracy:\n",
    "    best_accuracy = accuracy\n",
    "    best_model = model\n",
    "    \n",
    "print(f\"Mejor modelo hasta ahora: {best_model}, con una exactitud de: {best_accuracy}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La regresión logística, con una exactitud cercana a 0.68, no supera el desempeño del mejor modelo encontrado hasta ahora. Por lo tanto, el modelo de bosque aleatorio sigue siendo la mejor opción entre las probadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluación final: Comprobación de la calidad del modelo usando el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que hemos definido cuál es el mejor modelo, ahora se comprobará su calidad usando un conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(features_test) # Hacemos las predicciones del conjunto de prueba asignándolo a una nueva variable\n",
    "test_accuracy = accuracy_score(target_test, test_predictions) # Calculamos su puntaje de exactitud comparando las respuestas correctas con las predicciones\n",
    "print('Exactitud final en el conjunto de prueba:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "El modelo final (que resulto ser RandomForestClassifier(max_depth=10, n_estimators=8, random_state=54321)), alcanzó una exactitud aproximada de 0.82 en el conjunto de prueba. Esto sugiere que el modelo generaliza bien los datos nuevos al mismo tiempo que cumple y supera los objetivos de exactitud planteados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prueba de cordura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza una prueba de cordura para asegurar que el modelo mejore incluso si existen resultados triviales o aleatorios. Para ello, se compara el mejor modelo entrenado contra un modelo dummy que no utiliza la información de las características para predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\") # Creamos un modelo dummy que ignora las características y solo predice la clase mayoritaria de un conjunto de datos.\n",
    "dummy.fit(features_train, target_train) # 'Entrenamos' el modelo\n",
    "dummy_predictions = dummy.predict(features_test) # Hacemos las predicciones\n",
    "dummy_accuracy = accuracy_score(target_test, dummy_predictions) # Calculamos la exactitud\n",
    "print(\"Exactitud del modelo Dummy:\", dummy_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prueba de cordura utilizando un DummyClassifier que siempre predice la clase más frecuente dio una exactitud cercana al 0.72. Dado que el modelo RandomForestClassifier obtuvo un 0.82 en el conjunto de prueba, esto significa que el modelo sí está aprendiendo a partir de las características y supera significativamente una estrategia trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusión final del proyecto es que, tras evaluar distintos modelos supervisados de clasificación para machine learning -entre ellos árboles de decisión, bosques aleatorios y regresión logística—, el mejor desempeño se logró con un modelo de bosque aleatorio configurado con n_estimators=8 y max_depth =10. Este modelo alcanzó aproximadamente un 0.82 de exactitud en el conjunto de prueba, superando holgadamente el umbral requerido de 0.75. Además, la prueba de cordura con un modelo Dummy confirmó que el modelo seleccionado aprende relaciones útiles, ya que su exactitud fue superior a la de una predicción trivial."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 163,
    "start_time": "2024-12-15T22:59:55.105Z"
   },
   {
    "duration": 296,
    "start_time": "2024-12-15T23:00:09.861Z"
   },
   {
    "duration": 379,
    "start_time": "2024-12-15T23:00:12.855Z"
   },
   {
    "duration": 273,
    "start_time": "2024-12-15T23:00:27.947Z"
   },
   {
    "duration": 506,
    "start_time": "2024-12-15T23:00:28.222Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-15T23:00:53.431Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-15T23:01:23.514Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-15T23:02:58.094Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-15T23:03:04.001Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-15T23:04:00.524Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-15T23:04:25.834Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-15T23:12:03.454Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-15T23:12:13.527Z"
   },
   {
    "duration": 296,
    "start_time": "2024-12-15T23:12:20.670Z"
   },
   {
    "duration": 523,
    "start_time": "2024-12-15T23:12:20.970Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-15T23:12:46.599Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-15T23:21:45.110Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-15T23:22:03.170Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-15T23:22:25.385Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-15T23:23:11.558Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T23:23:16.708Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-15T23:23:20.687Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T23:23:30.678Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-15T23:23:59.256Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-15T23:24:24.767Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-15T23:24:49.229Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-15T23:24:55.953Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-15T23:25:03.695Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-15T23:25:07.085Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-15T23:26:24.986Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-16T00:36:18.345Z"
   },
   {
    "duration": 770,
    "start_time": "2024-12-16T00:36:30.499Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-16T00:36:31.271Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-16T00:36:31.285Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-16T00:36:31.296Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-16T00:50:13.619Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-16T01:01:52.037Z"
   },
   {
    "duration": 215,
    "start_time": "2024-12-16T01:21:30.091Z"
   },
   {
    "duration": 759,
    "start_time": "2024-12-16T01:21:37.222Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-16T01:21:37.983Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-16T01:21:37.998Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-16T01:21:38.015Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-16T01:21:38.020Z"
   },
   {
    "duration": 297,
    "start_time": "2024-12-16T01:21:38.027Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-16T01:22:59.917Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-16T01:23:17.238Z"
   },
   {
    "duration": 126,
    "start_time": "2024-12-16T01:24:28.520Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-16T01:27:25.566Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-16T01:28:04.999Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-16T01:28:08.583Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-16T01:28:52.729Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:29:57.830Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:30:12.666Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-16T01:30:31.850Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:30:39.787Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:30:39.987Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-16T01:30:46.207Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-16T01:30:55.561Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-16T01:35:42.993Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:36:01.174Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-16T01:48:30.443Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-16T01:49:59.180Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-16T01:50:41.086Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T01:50:59.282Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-16T01:51:22.783Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-16T01:58:24.337Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-16T01:58:28.476Z"
   },
   {
    "duration": 1294,
    "start_time": "2024-12-16T01:58:30.847Z"
   },
   {
    "duration": 1397,
    "start_time": "2024-12-16T01:59:25.841Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-16T01:59:37.483Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-16T01:59:49.569Z"
   },
   {
    "duration": 1246,
    "start_time": "2024-12-16T01:59:57.642Z"
   },
   {
    "duration": 1243,
    "start_time": "2024-12-16T02:00:14.272Z"
   },
   {
    "duration": 1228,
    "start_time": "2024-12-16T02:00:41.752Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-16T02:02:06.385Z"
   },
   {
    "duration": 170,
    "start_time": "2024-12-16T02:02:18.301Z"
   },
   {
    "duration": 1277,
    "start_time": "2024-12-16T02:02:24.662Z"
   },
   {
    "duration": 1251,
    "start_time": "2024-12-16T02:03:25.933Z"
   },
   {
    "duration": 1256,
    "start_time": "2024-12-16T02:03:30.894Z"
   },
   {
    "duration": 1249,
    "start_time": "2024-12-16T02:03:37.710Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-16T02:03:50.051Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-16T02:04:28.406Z"
   },
   {
    "duration": 1203,
    "start_time": "2024-12-16T02:04:32.499Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-16T02:04:51.219Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-16T02:05:11.742Z"
   },
   {
    "duration": 1236,
    "start_time": "2024-12-16T02:05:18.104Z"
   },
   {
    "duration": 1252,
    "start_time": "2024-12-16T02:07:29.974Z"
   },
   {
    "duration": 1263,
    "start_time": "2024-12-16T02:07:45.889Z"
   },
   {
    "duration": 1242,
    "start_time": "2024-12-16T02:09:56.762Z"
   },
   {
    "duration": 1252,
    "start_time": "2024-12-16T02:10:09.109Z"
   },
   {
    "duration": 224,
    "start_time": "2024-12-17T17:13:17.593Z"
   },
   {
    "duration": 799,
    "start_time": "2024-12-17T17:13:22.954Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-17T17:13:23.755Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-17T17:13:23.773Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-17T17:13:23.785Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-17T17:13:23.790Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-17T17:13:23.797Z"
   },
   {
    "duration": 1308,
    "start_time": "2024-12-17T17:13:23.894Z"
   },
   {
    "duration": 1294,
    "start_time": "2024-12-17T17:14:36.492Z"
   },
   {
    "duration": 74,
    "start_time": "2024-12-17T17:15:25.357Z"
   },
   {
    "duration": 1353,
    "start_time": "2024-12-17T17:15:57.989Z"
   },
   {
    "duration": 1291,
    "start_time": "2024-12-17T17:16:21.208Z"
   },
   {
    "duration": 1296,
    "start_time": "2024-12-17T17:16:39.679Z"
   },
   {
    "duration": 73,
    "start_time": "2024-12-17T17:16:48.543Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-17T17:16:54.239Z"
   },
   {
    "duration": 1499,
    "start_time": "2024-12-17T17:17:05.447Z"
   },
   {
    "duration": 1268,
    "start_time": "2024-12-17T17:17:11.145Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-17T17:18:50.697Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-17T17:25:42.475Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-17T17:27:21.612Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-17T17:28:23.402Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-17T17:28:36.375Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-17T17:39:14.507Z"
   },
   {
    "duration": 281,
    "start_time": "2024-12-17T17:39:21.256Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-17T17:39:30.414Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-17T17:58:37.359Z"
   },
   {
    "duration": 75,
    "start_time": "2024-12-17T18:01:56.858Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-17T18:02:36.123Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-17T18:34:42.791Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-17T18:34:57.190Z"
   },
   {
    "duration": 1255,
    "start_time": "2024-12-17T19:24:49.030Z"
   },
   {
    "duration": 1259,
    "start_time": "2024-12-17T19:28:42.658Z"
   },
   {
    "duration": 1255,
    "start_time": "2024-12-17T19:30:03.226Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-17T19:48:55.620Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-17T19:48:56.897Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-17T19:49:07.410Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
